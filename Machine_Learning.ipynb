{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1 :  What is the difference between AI, ML, DL, and Data Science? Provide a brief explanation of each.\n",
        "\n",
        "Artificial Intelligence (AI) is the broad science of mimicking human abilities, covering any technique that enables computers to mimic human intelligence.​\n",
        "\n",
        "Machine Learning (ML) is a subset of AI focusing on learning from data to make predictions or decisions without being explicitly programmed.​\n",
        "\n",
        "Deep Learning (DL) is a subset of ML that uses neural networks with many layers, excelling in processing unstructured data like images and text.​\n",
        "\n",
        "Data Science is the field of extracting insights and knowledge from data using statistics, programming, domain knowledge, and includes ML as a key tool"
      ],
      "metadata": {
        "id": "pfuH7yA8iWF5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain overfitting and underfitting in ML. How can you detect and prevent them?\n",
        "\n",
        "Overfitting means a model fits the training data too well, including noise, failing to generalize to new data (high variance).​\n",
        "\n",
        "Underfitting means a model is too simple to capture the data patterns (high bias).​\n",
        "\n",
        "Detection: Compare training and validation scores. Overfit models have large gaps (high on train, low on val). Underfit models perform poorly on both.​\n",
        "\n",
        "Prevention: Use cross-validation, limit model complexity, add regularization (e.g., L1/L2), and gather more data"
      ],
      "metadata": {
        "id": "H_HklwOLieDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3:How would you handle missing values in a dataset? Explain at least three methods with examples.\n",
        "\n",
        "Deletion: Remove rows/columns with missing data when they're few.​\n",
        "\n",
        "Imputation: Replace missing values with mean/median for numerical, mode for categorical. For example, fill NaNs in age with median age.​\n",
        "\n",
        "Predictive Imputation: Model missing values using algorithms (e.g., regress salary from age, education), filling gaps based on correlations"
      ],
      "metadata": {
        "id": "ETUa5eEeiiuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4:What is an imbalanced dataset? Describe two techniques to handle it (theoretical + practical)\n",
        "\n",
        "\n",
        "Imbalance: Class distributions are very uneven (e.g., 90:10).​\n",
        "\n",
        "Techniques:\n",
        "\n",
        "SMOTE: Generates synthetic minority samples.\n",
        "\n",
        "Random Under/Oversampling: Remove majority or duplicate minority data.​\n",
        "\n",
        "Class Weighting: Give higher penalty to minority class errors."
      ],
      "metadata": {
        "id": "uRtZftakioZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Why is feature scaling important in ML? Compare Min-Max scaling and Standardization.\n",
        "\n",
        "Min-Max scaling and Standardization are two of the most common feature scaling techniques, and the right choice depends on the dataset and the algorithm. Min-Max scaling (Normalization) This method rescales features to a fixed range, typically \\([0,1]\\). Formula:\\(X_{\\text{scaled}}=\\frac{X-X_{\\text{min}}}{X_{\\text{max}}-X_{\\text{min}}}\\) \\(X\\): The original feature value.\\(X_{\\text{min}}\\): The minimum value of the feature.\\(X_{\\text{max}}\\): The maximum value of the feature. When to use it: When the data distribution is unknown or is not Gaussian.For algorithms that require input features to be on a bounded scale, such as neural networks and fuzzy logic.When the data has minimal or no significant outliers, as Min-Max scaling is highly sensitive to them. Standardization (Z-score normalization) Standardization transforms data to have a mean of 0 and a standard deviation of 1 using the formula:\\(X_{\\text{scaled}}=\\frac{X-\\mu }{\\sigma }\\)where \\(X\\) is the original feature value, \\(\\mu \\) is the mean, and \\(\\sigma \\) is the standard deviation. This method is suitable for algorithms assuming normally distributed data, algorithms robust to outliers, and PCA"
      ],
      "metadata": {
        "id": "iSD8UTjaiwgK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6:  Compare Label Encoding and One-Hot Encoding. When would you prefer one over the other?\n",
        "\n",
        "Label Encoding: Assign numbers to categories; best for ordinal data (e.g., \"Low\", \"Medium\", \"High\").​\n",
        "\n",
        "One-Hot Encoding: Binary columns per category; best for nominal data (no order, e.g., \"Color\").​\n",
        "\n",
        "Prefer One-Hot for non-ordinal as Label creates artificial order"
      ],
      "metadata": {
        "id": "SBbapn9ajQKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 7:  Google Play Store Dataset a). Analyze the relationship between app categories and ratings. Which categories have the highest/lowest average ratings, and what could be the possible reasons?\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv('googleplaystore.csv')\n",
        "cat_avg = df.groupby('Category')['Rating'].mean().sort_values(ascending=False)\n",
        "print(cat_avg)"
      ],
      "metadata": {
        "id": "qynpn1W3jmHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 8: Titanic Dataset a) Compare the survival rates based on passenger class (Pclass). Which class had the highest survival rate, and why do you think that happened? b) Analyze how age (Age) affected survival. Group passengers into children (Age < 18) and adults (Age ≥ 18). Did children have a better chance of survival?\n",
        "\n",
        "df = pd.read_csv('titanic.csv')\n",
        "print(df.groupby('Pclass')['Survived'].mean())\n",
        "\n",
        "\n",
        "df['AgeGroup'] = df['Age'].apply(lambda x: 'Child' if x < 18 else 'Adult')\n",
        "print(df.groupby('AgeGroup')['Survived'].mean())\n"
      ],
      "metadata": {
        "id": "3G3X759cjtW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 9: Flight Price Prediction Dataset a) How do flight prices vary with the days left until departure? Identify any exponential price surges and recommend the best booking window. b)Compare prices across airlines for the same route (e.g., Delhi-Mumbai). Which airlines are consistently cheaper/premium, and why?\n",
        "##a\n",
        "df = pd.read_csv('flight_price.csv')\n",
        "import seaborn as sns\n",
        "sns.lineplot(x='days_left', y='price', data=df)\n",
        "\n",
        "\n",
        "##b\n",
        "route = df[(df['source']=='Delhi') & (df['destination']=='Mumbai')]\n",
        "print(route.groupby('airline')['price'].mean())\n",
        "\n"
      ],
      "metadata": {
        "id": "tNKsW1hLj5Jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Question 10:  HR Analytics Dataset a). What factors most strongly correlate with employee attrition? Use visualizations to show key drivers (e.g., satisfaction, overtime, salary). b). Are employees with more projects more likely to leave?\n",
        "df = pd.read_csv('hr_analytics.csv')\n",
        "print(df.corr()['left'].sort_values(ascending=False))\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "sns.boxplot(x='left', y='satisfaction_level', data=df)\n",
        "\n",
        "sns.barplot(x='number_project', y='left', data=df)\n"
      ],
      "metadata": {
        "id": "XsCR_aqlkEwv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}